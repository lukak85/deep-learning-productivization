name: "sloberta"
platform: "pytorch_libtorch"
max_batch_size : 0
input {
  name: "attention_mask"
  data_type: TYPE_INT64
  dims: [1, -1]
}
input {
  name: "input_ids"
  data_type: TYPE_INT64
  dims: [1, -1]
}
output {
  name: "logits"
  data_type: TYPE_FP32
  dims: [2, -1]
}